@article{covidnet,
	title        = {
		{COVID-Net}: a tailored deep convolutional neural network design for detection
		of {COVID-19} cases from chest {X}-ray images
	},
	author       = {Wang, Linda and Lin, Zhong Qiu and Wong, Alexander},
	year         = 2020,
	month        = {November},
	day          = 11,
	journal      = {Scientific Reports},
	volume       = 10,
	number       = 1,
	pages        = 19549,
	doi          = {10.1038/s41598-020-76550-z},
	issn         = {2045-2322},
	url          = {https://doi.org/10.1038/s41598-020-76550-z},
	abstract     = {
		The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a
		devastating effect on the health and well-being of the global population. A
		critical step in the fight against COVID-19 is effective screening of
		infected patients, with one of the key screening approaches being radiology
		examination using chest radiography. It was found in early studies that
		patients present abnormalities in chest radiography images that are
		characteristic of those infected with COVID-19. Motivated by this and
		inspired by the open source efforts of the research community, in this study
		we introduce COVID-Net, a deep convolutional neural network design tailored
		for the detection of COVID-19 cases from chest X-ray (CXR) images that is
		open source and available to the general public. To the best of the authors'
		knowledge, COVID-Net is one of the first open source network designs for
		COVID-19 detection from CXR images at the time of initial release. We also
		introduce COVIDx, an open access benchmark dataset that we generated
		comprising of 13,975 CXR images across 13,870 patient patient cases, with the
		largest number of publicly available COVID-19 positive cases to the best of
		the authors' knowledge. Furthermore, we investigate how COVID-Net makes
		predictions using an explainability method in an attempt to not only gain
		deeper insights into critical factors associated with COVID cases, which can
		aid clinicians in improved screening, but also audit COVID-Net in a
		responsible and transparent manner to validate that it is making decisions
		based on relevant information from the CXR images. By no means a
		production-ready solution, the hope is that the open access COVID-Net, along
		with the description on constructing the open source COVIDx dataset, will be
		leveraged and build upon by both researchers and citizen data scientists
		alike to accelerate the development of highly accurate yet practical deep
		learning solutions for detecting COVID-19 cases and accelerate treatment of
		those who need it the most.
	}
}
@article{covidnet-debunk,
	title        = {{AI} for radiographic {COVID-19} detection selects shortcuts over signal},
	author       = {DeGrave, Alex J. and Janizek, Joseph D. and Lee, Su-In},
	year         = 2021,
	month        = {Jul},
	day          = {01},
	journal      = {Nature Machine Intelligence},
	volume       = 3,
	number       = 7,
	pages        = {610--619},
	doi          = {10.1038/s42256-021-00338-7},
	issn         = {2522-5839},
	url          = {https://doi.org/10.1038/s42256-021-00338-7},
	abstract     = {
		Artificial intelligence (AI) researchers and radiologists have recently
		reported AI systems that accurately detect COVID-19 in chest radiographs.
		However, the robustness of these systems remains unclear. Using
		state-of-the-art techniques in explainable AI, we demonstrate that recent
		deep learning systems to detect COVID-19 from chest radiographs rely on
		confounding factors rather than medical pathology, creating an alarming
		situation in which the systems appear accurate, but fail when tested in new
		hospitals. We observe that the approach to obtain training data for these AI
		systems introduces a nearly ideal scenario for AI to learn these spurious
		`shortcuts'. Because this approach to data collection has also been used to
		obtain training data for the detection of COVID-19 in computed tomography
		scans and for medical imaging tasks related to other diseases, our study
		reveals a far-reaching problem in medical-imaging AI. In addition, we show
		that evaluation of a model on external data is insufficient to ensure AI
		systems rely on medically relevant pathology, because the undesired
		`shortcuts' learned by AI systems may not impair performance in new
		hospitals. These findings demonstrate that explainable AI should be seen as a
		prerequisite to clinical deployment of machine-learning healthcare models.
	}
}
@misc{data-analysis-shortage,
	title        = {Data analytics skills shortage in tech},
	author       = {Ramachandran, Karthik and Watson, Jeanette},
	year         = 2021,
	month        = {March},
	howpublished = {
		\url{https://www2.deloitte.com/us/en/insights/industry/technology/data-analytics-skills-shortage.html}
	}
}
@inproceedings{amazon-reviews,
	title        = {
		Justifying recommendations using distantly-labeled reviews and fined-grained
		aspects
	},
	author       = {Ni, Jianmo and Li, Jiacheng and McAuley, Julian},
	year         = 2019,
	booktitle    = {Empirical Methods in Natural Language Processing (EMNLP)}
}
