\documentclass{csse4400}

% \teachermodetrue

\usepackage{float}

\usepackage{languages}

\title{Docker and Docker Compose}
\author{Brae Webb \& Evan Hughes}

\date{\week{3}}
\begin{document}

\maketitle

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.4]{images/docker}
  \end{center}
  \caption{Docker containers by MidJourney with Prompt ""}
\end{figure}

\section{This Week}
This week our goal is to:
\begin{itemize}
  \item Learn docker basics.
  \item Dockerise our Todo application from last week.
  \item Move to a postgresql database from the SQLite database we used last week.
  \item Testing and Packaging our application on commit.
\end{itemize}

\pagebreak
\section{Getting Started with Docker}

In the lectures we have delved into the world of containers and how they can be used to create a consistent environment for our applications. Depending on the courses you have taken you may have been exposed to them as either a user or a consumer, for instance if you have submitted assessment to gradescope in CSSE1001 or CSSE2002 the submission system uses docker to run your code.\\

\notice{
This practical will assume you have not used docker before but we will be skipping over some aspects since its not needed for our purposes. Please see the lectures if you would like a better overview to containerisation.
}

\teacher{
  Sections 2.1 and 2.2 are presentation based where you should be covering the fundementals of docker images and containers. Where we are using container to describe the implemented image running in an environment.
}

\subsection{Docker Images}

Images are the building block of the principals on containerisation. They are a self contained environment that can be run that contains the depenedencies and code for an application. A common way to build an image is to use a Dockerfile. Though Docker was not the first to make this concept, it is very popular and relativly easy to use.

\subsubsection{Dockerfile}

The Dockerfile is a plain text file with its own markup language that is used to describe the image. It is a series of instructions that are run in order to build the image. The instructions are run in a layered fashion, each instruction is run on top of the previous instruction. This means that if you change a line in the Dockerfile you only need to rebuild the layers that have changed. This is a huge time saver when developing your application.

A reference of all possible Dockerfile instructions can be found here: \url{https://docs.docker.com/engine/reference/builder/}. For the purposes of the course we are just gonna cover some of the basics of [FROM, RUN, COPY, ADD, WORKDIR, CMD, ENTRYPOINT]

\begin{description}
  \item[FROM] The FROM instruction initializes a new build stage and sets the Base Image for subsequent instructions. As such, a valid Dockerfile must start with a FROM instruction. \cite{Dockerfile}
\end{description}

\begin{code}[language=docker,numbers=none]{}
# syntax=docker/dockerfile:1
FROM ubuntu:latest
\end{code}

When building a Dockerfile you need to start with a base image. This is the image that you will build on top of. In this case we are using the latest version of ubuntu. This ubutu is a very minimal image that is used intended to be used as a starting point and is itself an image.

\begin{description}
  \item[RUN] The RUN instruction will execute any commands in a new layer on top of the current image and commit the results. The resulting committed image will be used for the next step in the Dockerfile. \cite{Dockerfile}
\end{description}

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip
\end{code}

As stated in the definition, the RUN command allows us to perform actions that will happen when the container is built. The example above is installing python dependencies for a fake application. When installing software through a traditional package manager dont forget to update the package list first.

\begin{description}
  \item[COPY] The COPY instruction copies new files or directories from <src> and adds them to the filesystem of the container at the path <dest>. \cite{Dockerfile}
\end{description}

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Copying our application into the container
  COPY fan-club-runner /app
\end{code}

The copy command is one way to pull in resources into the container and is probably the simpliest way. This command allows copying individual files and you can also copy entire directories. Do be aware that when you COPY files in they will exist in the layer forever. The following example will still expose the secrets.txt file even though we removed it in another layer.

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Copying our application into the container
  COPY fan-club-runner /app

  # Removing the secrets file
  RUN rm /app/secrets.txt
\end{code}

\begin{description}
  \item[ADD] The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the image at the path <dest>. \cite{Dockerfile}
\end{description}

ADD can behave like COPY but it can also pull in files and tars from remote locations. This can be handy if your application requires external static files and you dont want to store them in your git repository. Though the ADD command is usually not recommended and is often replaced with curl or wget.

\begin{description}
  \item[WORKDIR] The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile. If the WORKDIR doesn't exist, it will be created even if it's not used in any subsequent Dockerfile instruction. \cite{Dockerfile}
\end{description}

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Setting the working directory
  WORKDIR /app

  # Copying our application into the container
  COPY fan-club-runner .
\end{code}

The WORKDIR command is a friendly readability feature to help you reduce the amount of shuffling around within the container.
\begin{description}
  \item[ENTRYPOINT] An ENTRYPOINT allows you to configure a container that will run as an executable. \cite{Dockerfile}
\end{description}

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Setting the working directory
  WORKDIR /app

  # Copying our application into the container
  COPY fan-club-runner .

  # Setting the default command
  ENTRYPOINT ["python3", "fan-club-runner.py"]
\end{code}

The ENTRYPOINT instruction is the executable that will be run when the container starts. The CMD instruction accompanises the ENTRYPOINT and is the default arguments that will be passed to the ENTRYPOINT.

\begin{code}[language=shell,numbers=none]{}
  docker run test
\end{code}

example output:

\begin{code}[language=shell,numbers=none]{}
  Richard Thomas Fan Club!
\end{code}

\begin{description}
  \item[CMD] The main purpose of a CMD is to provide defaults for an executing container. \cite{Dockerfile}
\end{description}

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Setting the working directory
  WORKDIR /app

  # Copying our application into the container
  COPY fan-club-runner .

  # Setting the default command
  ENTRYPOINT ["python3", "fan-club-runner.py"]
  CMD ["--help"]
\end{code}

As stated above the CMD instruction sets default parameters for the ENTRYPOINT but is easily overriden when the container is run. The following example will override the default --help argument and run the application with the --version argument.

\begin{code}[language=shell,numbers=none]{}
  docker run test --version
\end{code}

example output:

\begin{code}[language=shell,numbers=none]{}
  Fan Club Runner 1.0.0
\end{code}

That concludes the docker instructions we will be looking at so far but there are more that you may need to explore in the future. The full list of instructions can be found in the official documentation \cite{Dockerfile}.

\subsubsection{Dockerfile Layers}

In the previous sections we have been using the RUN, ADD and COPY to build up our image to run an example application. When the container is built each of these instructions is run on a layer of the image. This means that if you change a line in the Dockerfile you only need to rebuild the layers that have changed. This is a huge time saver when developing your application.

Lets have a look at an example of the layers that are created when we build our Dockerfile from the previous section.

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Copying our application into the container
  COPY . /app

  # Installing our application dependencies
  RUN pip3 install -r /app/requirements.txt

  # Setting the working directory
  WORKDIR /app

  # Running our application
  CMD ["python3", "src/app.py"]
\end{code}

We see that we are copying in the entire application directory before we install our requirements. We can improve this so that we only copy in the requirements file and then install the requirements. This means that if we change our application code we don't need to reinstall the requirements.

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Copying our application into the container
  COPY requirements.txt /app/requirements.txt

  # Installing our application dependencies
  RUN pip3 install -r /app/requirements.txt

  # Copying our application into the container
  COPY src/ /app

  # Setting the working directory
  WORKDIR /app

  # Running our application
  CMD ["python3", "src/app.py"]
\end{code}

For the containers we will be building this may not be a large issue, but once your project becomes larger and you have more dependencies it can become a large time saver.

To see the layers that are created when you build your Dockerfile you can use the following command:

\begin{code}[language=bash,numbers=none]{}
  docker history <image name>

  # Example
  docker history ubuntu:latest
\end{code}


\subsubsection{Image Registries}

When we introduced the Dockerfile we glossed over the details of where \texttt{ubuntu:latest} is being sourced from. This image is coming from a registry. There are a few different registries that you can use. The default registry is one hosted by Docker themselves. This is the registry that is used when you don't specify a registry and is available at \url{https://hub.docker.com/}. There are also registries hosted by other companies such as Google and Amazon. These are available at \url{https://cloud.google.com/container-registry} and \url{https://aws.amazon.com/ecr/} respectively.

As an example the image that we have been using is available at \url{https://hub.docker.com/_/ubuntu}. When browsing this page we can also see differnt tags that are available for this image, such as \texttt{latest} and \texttt{20.04}. These tags are used to specify different versions of the image so you can pin your image instead of using the \texttt{latest} tag which will always point to the latest version of the image. Note that not all images will have different tags or even a \texttt{latest} tag.

\begin{figure}[H]
  \includegraphics[width=\textwidth]{images/dockerhub}
  \caption{Ubuntu image on Docker Hub}
\end{figure}

\subsection{Docker Containers}

\todo{continue fleshing this out}

\subsubsection{Docker Networking}

\todo{continue fleshing this out}

\subsubsection{Docker Volumes}

\todo{continue fleshing this out}

\subsection{Installing Docker}

To install docker on your Mac or Windows machine you can follow the instructions on the docker website: \url{https://docs.docker.com/get-docker/}. If you are using a Linux machine you can install docker using your package manager. For example on Ubuntu you can use the following command:

\begin{code}[language=bash,numbers=none]{}
  sudo apt-get install docker.io
\end{code}

\info{
  If you are using a Linux machine you may need to add your user to the docker group so that you can run docker commands without sudo. While the docker website suggests using docker-desktop for Linux, the course highly recommends using the native docker installation.
}


\subsection{Running a Docker Container}

To verify that docker is installed correctly you can run the following command:

\begin{code}[language=bash,numbers=none]{}
  docker run hello-world

  # Example output
  ...

  Hello from Docker!
  This message shows that your installation appears to be working correctly.
\end{code}


\section{Dockerising our Todo Application}

\teacher{
  For this section let the students work through the practical on their own. The content above should be enough to guide them through the process with the provided instructions.
}

\subsection{Creating a Practical Repository}
Navigate to the GitHub Classroom link for this practical provided by your tutor in Slack.
As with last week, this will create a new repository for you in the course organisation.
You can now clone this repository to your local machine or work directly in the browser with GitHub codespaces.
This repository will be populated with our solution to last weeks practical exercise.
You may modify this solution or replace it with your own.

\subsection{Creating a Dockerfile}

Now that we have covered the basics of Docker we can Dockerise our Todo App to prepare it for deployment. Inside our practical folder we will create a new file called \texttt{Dockerfile}. To start us off we will use the following Dockerfile:

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip
\end{code}

The above image is what your local environments may have been like when you started the course. To follow the same setup as we have had in the practicals lets install pipenv. We can do this by adding the following line to our Dockerfile:

\begin{code}[language=docker,numbers=none]{}
  # Install pipenv
  RUN pip3 install -y pipenv
\end{code}

Lets now change our working directory to \texttt{/app} and copy our \texttt{Pipfile} and \texttt{Pipfile.lock} into the container. We can then install our dependencies using pipenv. We can do this by adding the following lines to our Dockerfile:

\begin{code}[language=docker,numbers=none]{}
  # Setting the working directory
  WORKDIR /app

  # Install pipenv dependencies
  COPY Pipfile Pipfile.lock /app/
  RUN pipenv install --system --deploy
\end{code}

Now that we have installed our dependencies we can copy our application into the container. We can do this by adding the following line to our Dockerfile:

\begin{code}[language=docker,numbers=none]{}
  # Copying our application into the container
  COPY todo/ /app

\end{code}

Finally we can run our application by adding the following line to our Dockerfile:

\begin{code}[language=docker,numbers=none]{}
  # Running our application
  CMD ["python3", "flask", "--app", "todo", "run", "--host", "0.0.0.0", "--port", "6400"]
\end{code}

We should now have a complete Dockerfile, as shown below:

\begin{code}[language=docker,numbers=none]{}
  # syntax=docker/dockerfile:1
  FROM ubuntu:latest

  # Installing dependencies for running a python application
  RUN apt-get update && apt-get install -y python3 python3-pip

  # Install pipenv
  RUN pip3 install -y pipenv

  # Setting the working directory
  WORKDIR /app

  # Install pipenv dependencies
  COPY Pipfile Pipfile.lock /app/
  RUN pipenv install --system --deploy

  # Copying our application into the container
  COPY todo/ /app
  
  # Running our application
  CMD ["python3", "flask", "--app", "todo", "run", "--host", "0.0.0.0", "--port", "6400"]
\end{code}

\subsection{Building our Docker Image}

Now that we have created our Dockerfile we can build our Docker image. To do this we will use the following command:

\begin{code}[language=bash,numbers=none]{}
  docker build -t todo .

  # Example output
  ...
  Successfully tagged todo:latest
\end{code}

We can then inspect our layers with the following command:

\begin{code}[language=bash,numbers=none]{}
  docker image history todo
\end{code}


\subsection{Running our Docker Container}

Now that we have built our Docker image we can run our Docker container. To do this we will use the following command:

\begin{code}[language=bash,numbers=none]{}
  docker run -p 6400:6400 todo

  # Example output
  ...
  * Running on ...
\end{code}

We can now navigate to \url{http://localhost:6400} to see our application running. We can stop our container by pressing \texttt{Ctrl+C}. This should show the todo app that we have been working with for the past couple of practicals.

\info{
  It is important for us to use the host of 0.0.0.0 when running our application. This is because we are running our application inside a container and we need to expose the port to the host machine. If we were to use the default host of 127.0.0.1 we would not be able to access our application from outside the container.
}

\warning{
  You do need to make sure that you were not running the webserver from the previous practical on port 6400. If you were you will need to stop that webserver before running the docker container. If you also have other containers running they can conflict with this container.
}

\subsection{Docker Compose}

Docker is a useful tool itself but in terms of local development, Docker Compose is a much more useful tool. Docker Compose allows us to run multiple containers together which can be extremely useful if your developing multiple projects or have multiple components that need to be put together. For instance for a story close to home, maybe you are working on INFS2200 with you database schema in one container and you can be running your DECO3801 projects database in another container. 

For us, we are going to be using a database closer to our production environment. We will be using a Postgresql database which will eventually be a managed database hosted option from AWS.

\subsection{Moving to a Postgresql Database}

This week we have actually made a small change to our application so that it can receive the SQLAlchemy database URI as an environment variable. This means that we can now use Docker Compose to run our application and database together. To do this we will create a new file called \texttt{docker-compose.yml} and add the following content:

\begin{code}[numbers=none]{}
  version: "3.9"

  services:
    database:
      image: postgres:latest
      restart: always
      environment:
        POSTGRES_PASSWORD: verySecretPassword
        POSTGRES_USER: administrator
        POSTGRES_DB: todo
      volumes:
        - ./data:/var/lib/postgresql/data
    app:
      build: .
      restart: always
      environment:
        DATABASE_URI: postgresql://administrator:verySecretPassword@database:5432/todo
      ports:
        - "6400:6400"
      depends_on:
        - database
\end{code}

We can now run our application and database with the following command:

\begin{code}[language=bash,numbers=none]{}
  docker-compose up
\end{code}

You should observe the output of this command and you can see two processes running. One is the database and the other is our application. We can now navigate to \url{http://localhost:6400} to see our application running. In reality though our database probably did not have enough time to start up before our application tried to connect to it. We can fix this by adding a delay to our application startup. To do this we will add the following line to our Dockerfile:

\begin{code}[language=docker,numbers=none]{}
  # Adding a delay to our application startup
  CMD ["sleep", "10", "&&", "python3", "flask", "--app", "todo", "run", "--host", "0.0.0.0", "--port", "6400"]
\end{code}

In the long run you would want your application to be able to retry connecting to the database if it fails but for now we will just add a delay. We can now rebuild our Docker image and run our application and database with the following commands:

\begin{code}[language=bash,numbers=none]{}
  docker-compose up --build
\end{code}

You may have noticed that when we defined the todo application service above we didnt specify a container. This is because Docker Compose can be instructed to use our Dockerfile to build at time so that we dont have to keep using the build command.

% \section{Packaging our Application on Commit}

% \teacher{
%   Here we will describe the basics of CI for building our container, we teach this here so that next week we can start using it for the AWS deployment.
% }

% \todo{Running out of time so potentially cut this and move it to the week that we deploy our container}

% \subsection{Intro to Continuous Integration}


% \subsection{Intro to GitHub Actions}

% \subsection{Packaging on commit}

\section{Conclusion}

Over the past couple of weeks we have built a full todo api that is ready to be deployed to a remote environment. We started with a Flask API returning static responses and now we have a dynamic API that is running in a containerised environment with a external database.

The teaching team do want to emphasise that we have cheated with our docker deployment by using the flask development server. For a production environment you will want to use a production webserver such as gunicorn or uwsgi. These web servers are designed to handle multiple requests at the same time and are much more efficient than the flask development server. We recommend you have a look at how to productionise your flask application as it may help you in your future projects if you choose to use Flask.

\bibliographystyle{ieeetr}
\bibliography{books,ours,references}

\end{document}